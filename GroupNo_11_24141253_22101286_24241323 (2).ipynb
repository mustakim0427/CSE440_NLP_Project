{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##!wget http://nlp.stanford.edu/data/glove.6B.zip! unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "PldeF9Xx8YB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SETUP ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ast\n",
        "\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "Iac_u5VgS2hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LOAD DATA ---\n",
        "train_df = pd.read_csv('/content/Dataset_A_POS_train.csv')\n",
        "test_df = pd.read_csv('/content/Dataset_A_POS_test.csv')"
      ],
      "metadata": {
        "id": "NnJakuLFS9j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mPEM-Os-j688"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "print(\"\\nSample row:\\n\", train_df.iloc[0])\n",
        "print(\"\\nUnique POS sequences:\", train_df['POS'].nunique())"
      ],
      "metadata": {
        "id": "AobLuy81TAvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing glove model\n"
      ],
      "metadata": {
        "id": "OWc7X-IMTLfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = '/content/glove.6B.100d.txt'\n",
        "\n",
        "glove_embedding = {}\n",
        "with open(glove_path, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coeffs = np.array(values[1:], dtype='float32')\n",
        "        glove_embedding[word] = coeffs\n",
        "\n",
        "print(f\"Loaded {len(glove_embedding)} word vectors.\")\n"
      ],
      "metadata": {
        "id": "frUHkR-j8d6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Processing"
      ],
      "metadata": {
        "id": "SCRgtc_q2z1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['POS'] = train_df['POS'].apply(ast.literal_eval)\n",
        "\n",
        "\n",
        "all_tags = [tag for sentence in train_df['POS'] for tag in sentence]\n",
        "\n",
        "tag_counts = Counter(all_tags)\n",
        "\n",
        "print(\"Most Frequent POS Tags:\")\n",
        "print(tag_counts.unique)\n",
        "\n",
        "test_df['POS'] = test_df['POS'].apply(ast.literal_eval)"
      ],
      "metadata": {
        "id": "sdVMGty6TwDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "TdXFJV2_Tx9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PREPROCESSING ---\n",
        "train_sentences = train_df['Sentence'].tolist()\n",
        "test_sentences = test_df['Sentence'].tolist()\n",
        "train_tags = train_df['POS'].tolist()\n",
        "test_tags = test_df['POS'].tolist()"
      ],
      "metadata": {
        "id": "c5w3-1UFT3_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize words\n",
        "word_tokenizer = Tokenizer(lower=True, oov_token=\"<OOV>\")\n",
        "word_tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(train_sentences)\n",
        "X_test = word_tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "word_index = word_tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1"
      ],
      "metadata": {
        "id": "ZgnKMX-YUF4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize POS tags\n",
        "\"\"\"\"\n",
        "all_tags = set(tag for seq in train_tags for tag in seq)\n",
        "tag_tokenizer = Tokenizer(lower=False)\n",
        "tag_tokenizer.fit_on_texts([' '.join(seq) for seq in train_tags])\n",
        "y_train = tag_tokenizer.texts_to_sequences([' '.join(seq) for seq in train_tags])\n",
        "y_test = tag_tokenizer.texts_to_sequences([' '.join(seq) for seq in test_tags])\n",
        "tag_index = tag_tokenizer.word_index\n",
        "num_tags = len(tag_index) + 1\"\"\""
      ],
      "metadata": {
        "id": "aknwSZuzUHQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "flat_train_tags = [tag for sentence in train_tags for tag in sentence]\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(flat_train_tags)\n"
      ],
      "metadata": {
        "id": "39HBsxAjWKhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoded_train_tags = [le.transform(tags) for tags in train_tags]\n",
        "encoded_test_tags = [le.transform(tags) for tags in test_tags]"
      ],
      "metadata": {
        "id": "mdlyvDhnX59s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tags = len(le.classes_)"
      ],
      "metadata": {
        "id": "sW4MUbVgZ61t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "max_len = max(max(len(seq) for seq in X_train), max(len(seq) for seq in X_test))\n",
        "\n",
        "y_train = pad_sequences(encoded_train_tags, maxlen=max_len, padding='post', value = 0)\n",
        "y_test = pad_sequences(encoded_test_tags, maxlen=max_len, padding='post', value = 0)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len, padding='post', value = 0)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len, padding='post', value = 0)"
      ],
      "metadata": {
        "id": "QSBBJmMeXESr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_tags)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_tags)\n"
      ],
      "metadata": {
        "id": "YrguYiSQzDq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_len)"
      ],
      "metadata": {
        "id": "e9yx4NGa_DXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = glove_embedding.get(word)\n",
        "    if embedding_vector is not None:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "\n",
        "        pass\n",
        "\n",
        "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
      ],
      "metadata": {
        "id": "epYRIiBKiwRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (Input, Embedding, SimpleRNN, LSTM, GRU, Bidirectional,\n",
        "                                     Dense, TimeDistributed,Dropout)"
      ],
      "metadata": {
        "id": "QZ-QlGFEkGkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RNN\n"
      ],
      "metadata": {
        "id": "Tw3LXMBvjYa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- RNN MODEL ---\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(input_dim=vocab_size,\n",
        "                           output_dim=embedding_dim,\n",
        "                           weights=[embedding_matrix],\n",
        "                           input_length=max_len,\n",
        "                           trainable=False))\n",
        "model.add(layers.SimpleRNN(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.TimeDistributed(layers.Dense(num_tags, activation='softmax')))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.build(input_shape=(None, max_len))\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "eBUJuTwy0k3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TRAINING ---\n",
        "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "id": "QCthlqJYzQNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='validation Loss')\n",
        "plt.title('Model Loss Progression')\n",
        "plt.ylabel('categorical_crossentropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vgwn9xw0pc7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EVALUATION ---\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true_classes = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Flatten\n",
        "y_pred_flat = []\n",
        "y_true_flat = []\n",
        "\n",
        "for i in range(len(y_true_classes)):\n",
        "    for j in range(len(y_true_classes[i])):\n",
        "        if X_test[i][j] != 0:\n",
        "            y_pred_flat.append(y_pred_classes[i][j])\n",
        "            y_true_flat.append(y_true_classes[i][j])\n",
        "# Remove any 0s in true labels (padding tokens)\n",
        "filtered_true = []\n",
        "filtered_pred = []\n",
        "\n",
        "for true, pred in zip(y_true_flat, y_pred_flat):\n",
        "    if true != 0:  # 0 is padding\n",
        "        filtered_true.append(true)\n",
        "        filtered_pred.append(pred)\n",
        "\n",
        "# Recalculate label set and target names\n",
        "labels = sorted(set(filtered_true))\n",
        "idx_to_tag = {i: tag for i, tag in enumerate(le.classes_)}\n",
        "target_names = [idx_to_tag[i] for i in labels]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(filtered_true, filtered_pred, labels=labels, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(filtered_true, filtered_pred, labels=labels)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, xticklabels=target_names, yticklabels=target_names, cmap='Blues', annot=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "accuracy = accuracy_score(filtered_true, filtered_pred)\n",
        "f1_macro = f1_score(filtered_true, filtered_pred, average='macro')\n",
        "f1_weighted = f1_score(filtered_true, filtered_pred, average='weighted')\n",
        "\n",
        "# Accuracy and F1\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score (Macro):\", f1_macro)\n",
        "print(\"F1 Score (Weighted):\", f1_weighted)\n"
      ],
      "metadata": {
        "id": "9mwFfKEi1B61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "_tiEClnF25lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LSTM MODEL ---\n",
        "lstm = models.Sequential()\n",
        "\n",
        "lstm.add(layers.Embedding(input_dim=vocab_size,\n",
        "                          output_dim=embedding_dim,\n",
        "                          weights=[embedding_matrix],\n",
        "                          input_length=max_len,\n",
        "                          trainable=False))\n",
        "\n",
        "\n",
        "lstm.add(layers.LSTM(64, return_sequences=True))\n",
        "\n",
        "lstm.add(layers.Dropout(0.1))\n",
        "\n",
        "lstm.add(layers.TimeDistributed(layers.Dense(num_tags, activation='softmax')))\n",
        "\n",
        "lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "lstm.build(input_shape=(None, max_len))\n",
        "lstm.summary()"
      ],
      "metadata": {
        "id": "rNpmDkF8BW3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm1 = lstm.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "-FbZYwDmBeg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(history_lstm1.history['loss'], label='Training Loss')\n",
        "plt.plot(history_lstm1.history['val_loss'], label='validation Loss')\n",
        "plt.title('Model Loss Progression')\n",
        "plt.ylabel('categorical_crossentropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oUxNCvyv29rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EVALUATION ---\n",
        "y_pred =lstm.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true_classes = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Flatten\n",
        "y_pred_flat = []\n",
        "y_true_flat = []\n",
        "\n",
        "for i in range(len(y_true_classes)):\n",
        "    for j in range(len(y_true_classes[i])):\n",
        "        if X_test[i][j] != 0:\n",
        "            y_pred_flat.append(y_pred_classes[i][j])\n",
        "            y_true_flat.append(y_true_classes[i][j])\n",
        "# Remove any 0s in true labels (padding tokens)\n",
        "filtered_true = []\n",
        "filtered_pred = []\n",
        "\n",
        "for true, pred in zip(y_true_flat, y_pred_flat):\n",
        "    if true != 0:  # 0 is padding\n",
        "        filtered_true.append(true)\n",
        "        filtered_pred.append(pred)\n",
        "\n",
        "# Recalculate label set and target names\n",
        "labels = sorted(set(filtered_true))\n",
        "idx_to_tag = {i: tag for i, tag in enumerate(le.classes_)}\n",
        "target_names = [idx_to_tag[i] for i in labels]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(filtered_true, filtered_pred, labels=labels, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(filtered_true, filtered_pred, labels=labels)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, xticklabels=target_names, yticklabels=target_names, cmap='Blues', annot=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "lstm_accuracy = accuracy_score(filtered_true, filtered_pred)\n",
        "lstm_f1_macro = f1_score(filtered_true, filtered_pred, average='macro')\n",
        "lstm_f1_weighted = f1_score(filtered_true, filtered_pred, average='weighted')\n",
        "\n",
        "# Accuracy and F1\n",
        "print(\"Accuracy:\", lstm_accuracy)\n",
        "print(\"F1 Score (Macro):\", lstm_f1_macro)\n",
        "print(\"F1 Score (Weighted):\", lstm_f1_weighted)\n"
      ],
      "metadata": {
        "id": "gE3SEZWoBuXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "YZOzc60d1v7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GRU MODEL ---\n",
        "gru = models.Sequential()\n",
        "gru.add(layers.Embedding(input_dim=vocab_size,\n",
        "                           output_dim=embedding_dim,\n",
        "                           weights=[embedding_matrix],\n",
        "                           input_length=max_len,\n",
        "                           trainable=False))\n",
        "gru.add(layers.GRU(64, return_sequences=True))\n",
        "gru.add(layers.Dropout(0.1))\n",
        "gru.add(layers.TimeDistributed(layers.Dense(num_tags, activation='softmax')))\n",
        "\n",
        "gru.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "gru.build(input_shape=(None, max_len))\n",
        "gru.summary()\n"
      ],
      "metadata": {
        "id": "3Vk6Dy9ifCUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_gru = gru.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "-Iq-NVYefJgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(history_gru.history['loss'], label='Training Loss')\n",
        "plt.plot(history_gru.history['val_loss'], label='validation Loss')\n",
        "plt.title('Model Loss Progression')\n",
        "plt.ylabel('categorical_crossentropy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zMsXfLOT3P6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EVALUATION ---\n",
        "y_pred = gru.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true_classes = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Flatten\n",
        "y_pred_flat = []\n",
        "y_true_flat = []\n",
        "\n",
        "for i in range(len(y_true_classes)):\n",
        "    for j in range(len(y_true_classes[i])):\n",
        "        if X_test[i][j] != 0:\n",
        "            y_pred_flat.append(y_pred_classes[i][j])\n",
        "            y_true_flat.append(y_true_classes[i][j])\n",
        "# Remove any 0s in true labels (padding tokens)\n",
        "filtered_true = []\n",
        "filtered_pred = []\n",
        "\n",
        "for true, pred in zip(y_true_flat, y_pred_flat):\n",
        "    if true != 0:  # 0 is padding\n",
        "        filtered_true.append(true)\n",
        "        filtered_pred.append(pred)\n",
        "\n",
        "# Recalculate label set and target names\n",
        "labels = sorted(set(filtered_true))\n",
        "idx_to_tag = {i: tag for i, tag in enumerate(le.classes_)}\n",
        "target_names = [idx_to_tag[i] for i in labels]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(filtered_true, filtered_pred, labels=labels, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(filtered_true, filtered_pred, labels=labels)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, xticklabels=target_names, yticklabels=target_names, cmap='Blues', annot=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "gru_accuracy = accuracy_score(filtered_true, filtered_pred)\n",
        "gru_f1_macro = f1_score(filtered_true, filtered_pred, average='macro')\n",
        "gru_f1_weighted = f1_score(filtered_true, filtered_pred, average='weighted')\n",
        "# Accuracy and F1\n",
        "print(\"Accuracy:\", gru_accuracy)\n",
        "print(\"F1 Score (Macro):\", gru_f1_macro)\n",
        "print(\"F1 Score (Weighted):\", gru_f1_weighted)\n"
      ],
      "metadata": {
        "id": "nzxI4BhffLXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM"
      ],
      "metadata": {
        "id": "6dHeExA3rgpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bi_lstm = models.Sequential()\n",
        "bi_lstm.add(layers.Embedding(input_dim=vocab_size,\n",
        "                           output_dim=embedding_dim,\n",
        "                           weights=[embedding_matrix],\n",
        "                           input_length=max_len,\n",
        "                           trainable=False))\n",
        "bi_lstm.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True)))\n",
        "bi_lstm.add(layers.Dropout(0.1))\n",
        "bi_lstm.add(layers.TimeDistributed(layers.Dense(num_tags, activation='softmax')))\n",
        "\n",
        "bi_lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "bi_lstm.build(input_shape=(None, max_len))\n",
        "bi_lstm.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "jhaBqrnWkq03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_lstm = bi_lstm.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.1)"
      ],
      "metadata": {
        "id": "g9DFcJFilSw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_lstm.history['loss'], label='Training Loss')\n",
        "plt.plot(history_lstm.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('categorical_crossentropy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8Tk2Cypgrlve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EVALUATION ---\n",
        "y_pred = bi_lstm.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
        "y_true_classes = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Flatten\n",
        "y_pred_flat = []\n",
        "y_true_flat = []\n",
        "\n",
        "for i in range(len(y_true_classes)):\n",
        "    for j in range(len(y_true_classes[i])):\n",
        "        if X_test[i][j] != 0:\n",
        "            y_pred_flat.append(y_pred_classes[i][j])\n",
        "            y_true_flat.append(y_true_classes[i][j])\n",
        "# Remove any 0s in true labels (padding tokens)\n",
        "filtered_true = []\n",
        "filtered_pred = []\n",
        "\n",
        "for true, pred in zip(y_true_flat, y_pred_flat):\n",
        "    if true != 0:  # 0 is padding\n",
        "        filtered_true.append(true)\n",
        "        filtered_pred.append(pred)\n",
        "\n",
        "# Recalculate label set and target names\n",
        "labels = sorted(set(filtered_true))\n",
        "idx_to_tag = {i: tag for i, tag in enumerate(le.classes_)}\n",
        "target_names = [idx_to_tag[i] for i in labels]\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(filtered_true, filtered_pred, labels=labels, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(filtered_true, filtered_pred, labels=labels)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, xticklabels=target_names, yticklabels=target_names, cmap='Greens', annot=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "\n",
        "bi_lstm_accuracy = accuracy_score(filtered_true, filtered_pred)\n",
        "bi_lstm_f1_macro = f1_score(filtered_true, filtered_pred, average='macro')\n",
        "bi_lstm_f1_weighted = f1_score(filtered_true, filtered_pred, average='weighted')\n",
        "# Accuracy and F1\n",
        "print(\"Accuracy:\", bi_lstm_accuracy)\n",
        "print(\"F1 Score (Macro):\", bi_lstm_f1_macro)\n",
        "print(\"F1 Score (Weighted):\", bi_lstm_f1_weighted)"
      ],
      "metadata": {
        "id": "Aq1froU0mIhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Accuracy': [accuracy, lstm_accuracy, gru_accuracy, bi_lstm_accuracy],\n",
        "    'F1 Macro': [f1_macro,  lstm_f1_macro, gru_f1_macro,bi_lstm_f1_macro],\n",
        "    'F1 Weighted': [f1_weighted, lstm_f1_weighted, gru_f1_weighted, bi_lstm_f1_weighted]\n",
        "}\n",
        "model_names = ['Simple RNN', 'LSTM', 'GRU', 'BiLSTM']\n",
        "df_metrics = pd.DataFrame(data, index=model_names)\n",
        "\n",
        "# Set up the x locations and bar width\n",
        "x = np.arange(len(model_names))  # the label locations\n",
        "bar_width = 0.25  # width of each bar\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "colors = ['#FFA07A', '#ADD8E6', '#90EE90']\n",
        "# Plot each metric as a set of bars.\n",
        "rects1 = ax.bar(x - bar_width, df_metrics['Accuracy'], width=bar_width, label='Accuracy',color=colors[0])\n",
        "rects2 = ax.bar(x, df_metrics['F1 Macro'], width=bar_width, label='F1 Macro',color=colors[1])\n",
        "rects3 = ax.bar(x + bar_width, df_metrics['F1 Weighted'], width=bar_width, label='F1 Weighted',color=colors[2])\n",
        "\n",
        "# Add some text for labels, title and axes ticks.\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Performance Comparison of Models')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(model_names)\n",
        "ax.legend()\n",
        "\n",
        "# Optional: Label the bars with their heights.\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}',\n",
        "                    xy=(rect.get_x() + rect.get_width()/2, height),\n",
        "                    xytext=(0, 3),  # Vertical offset (3 points)\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "autolabel(rects3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "-ur3dYug1siB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgJi2WSy6lbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}